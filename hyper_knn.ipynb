{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN using Poincare Ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyptorch.nn import ToPoincare\n",
    "from hyptorch.pmath import dist as hypdist\n",
    "\n",
    "import numpy as np  # NumPy for numerical operations\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "from collections import Counter  # Counter for counting votes in the majority voting process\n",
    "import matplotlib.pyplot as plt  # Matplotlib for data visualization\n",
    "from matplotlib.colors import ListedColormap  # ListedColormap for custom color maps\n",
    "from sklearn import datasets  # Scikit-Learn for dataset loading\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO-LIST:\n",
    "# 1- Converter os dados para a bola de poincare; Check ✓\n",
    "# 2- Calcular a distancia na bola de poincare; Check ✓\n",
    "# 3- Validar se esta na bola de poincare;\n",
    "# 4- Plotar o CO-TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Code: https://github.com/mouraffa/KNN-From-Scratch-Iris-Classifier\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Implementação do KNN Euclidiano\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two data points x1 and x2.\n",
    "\n",
    "    Parameters:\n",
    "    x1 (numpy.ndarray): The first data point.\n",
    "    x2 (numpy.ndarray): The second data point.\n",
    "\n",
    "    Returns:\n",
    "    float: The Euclidean distance between x1 and x2.\n",
    "    \"\"\"\n",
    "    distance = np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "    return distance\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k: int = 3):\n",
    "        \"\"\"\n",
    "        Inicializa o classificador KNN.\n",
    "\n",
    "        Parâmetros:\n",
    "        k (int): O número de vizinhos a considerar (padrão é 3).\n",
    "        \"\"\"\n",
    "        if k <= 0:\n",
    "            raise ValueError(\"O número de vizinhos (k) deve ser positivo.\")\n",
    "        \n",
    "        self.k = k\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Treina o classificador KNN com os dados de treinamento.\n",
    "\n",
    "        Parâmetros:\n",
    "        X (numpy.ndarray): As características dos dados de treinamento.\n",
    "        y (numpy.ndarray): Os rótulos dos dados de treinamento.\n",
    "        \"\"\"\n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(\"O número de amostras em X e y deve ser o mesmo.\")\n",
    "        if X.shape[0] < self.k:\n",
    "            # Aviso ou erro, pois não haverá k vizinhos suficientes\n",
    "            print(f\"Aviso: O número de amostras de treinamento ({X.shape[0]}) é menor que k ({self.k}).\")\n",
    "\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X_test: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Prevê os rótulos para um conjunto de pontos de dados X_test.\n",
    "\n",
    "        Parâmetros:\n",
    "        X_test (numpy.ndarray): Os pontos de dados para os quais fazer previsões.\n",
    "\n",
    "        Retorna:\n",
    "        numpy.ndarray: Um array de rótulos previstos.\n",
    "        \"\"\"\n",
    "        if self.X_train is None or self.y_train is None:\n",
    "            raise RuntimeError(\"O classificador KNN deve ser treinado com o método 'fit' antes de prever.\")\n",
    "        \n",
    "        predictions = [self._predict_single(x) for x in X_test]\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def _predict_single(self, x: np.ndarray) -> int: # Renomeado para clareza e consistência\n",
    "        \"\"\"\n",
    "        Prevê o rótulo para um único ponto de dados x.\n",
    "\n",
    "        Parâmetros:\n",
    "        x (numpy.ndarray): O ponto de dados para o qual fazer uma previsão.\n",
    "\n",
    "        Retorna:\n",
    "        int: O rótulo previsto para o ponto de dados de entrada x.\n",
    "        \"\"\"\n",
    "        # Calcula as distâncias para todos os pontos de dados de treinamento\n",
    "        distances = [euclidean_distance(x, x_train_point) for x_train_point in self.X_train]\n",
    "\n",
    "        # Obtém os índices dos k pontos de dados de treinamento mais próximos\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "\n",
    "        # Obtém os rótulos dos k pontos de dados de treinamento mais próximos\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "\n",
    "        # Realiza a votação majoritária para determinar o rótulo final\n",
    "        # Counter(k_nearest_labels) cria um dict-like: {label: count}\n",
    "        # .most_common(1) retorna uma lista com uma tupla: [(most_common_label, count)]\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Implementação do KNN Hiperbólico (Modelo de Disco de Poincaré)\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "class HyperbolicKNN:\n",
    "    def __init__(self, k: int = 3, c: float = 0.5, validate_input_geometry: bool = True):\n",
    "        \"\"\"\n",
    "        Inicializa o classificador KNN Hiperbólico.\n",
    "\n",
    "        Parâmetros:\n",
    "        k (int): O número de vizinhos a considerar (padrão é 3).\n",
    "        c (float): Parâmetro de curvatura da bola de Poincaré (geralmente $c > 0$, onde\n",
    "                   a curvatura do espaço $K = -c$ ou $K = -c^2$ dependendo da convenção.\n",
    "                   Se o raio da bola é $1/\\\\sqrt{c_K}$ para curvatura $K > 0$, então\n",
    "                   esta `c` corresponde a $c_K$. Se o raio é $1/c_R$, então esta `c` é $c_R^2$.\n",
    "                   A validação usa $1/\\\\sqrt{c}$, então `c` é assumida como $K > 0$.\n",
    "        validate_input_geometry (bool): Se True, valida se os pontos estão na bola de Poincaré.\n",
    "        \"\"\"\n",
    "        if k <= 0:\n",
    "            raise ValueError(\"O número de vizinhos (k) deve ser positivo.\")\n",
    "        if c <= 0:\n",
    "            raise ValueError(\"O parâmetro de curvatura 'c' deve ser positivo para o modelo de Poincaré conforme usado na validação.\")\n",
    "        self.k = k\n",
    "        self.c = c\n",
    "        self.validate_input_geometry = validate_input_geometry\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def _validate_poincare_points(self, X: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Valida se os pontos de entrada estão dentro da bola de Poincaré.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Array de pontos, onde cada linha é um ponto.\n",
    "            curvature (float): A curvatura do espaço hiperbólico. Deve ser positiva.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: Se a curvatura não for positiva.\n",
    "            AssertionError: Se algum ponto estiver fora da bola de Poincaré\n",
    "                            definida por 1 / sqrt(curvature).\n",
    "        \"\"\"\n",
    "        if self.c <= 0:\n",
    "            raise ValueError(\"A curvatura (K) deve ser um valor positivo.\")\n",
    "        \n",
    "        max_norm_allowed = 1 / (self.c**0.5)\n",
    "        norms = np.linalg.norm(X, axis=1)\n",
    "\n",
    "        if not np.all(norms <= max_norm_allowed):\n",
    "            problematic_indices = np.where(norms > max_norm_allowed)[0]\n",
    "            error_msg = (\n",
    "                f\"Validação da geometria falhou! Pontos com índices {problematic_indices} \"\n",
    "                f\"estão fora da bola de Poincaré (norma > {max_norm_allowed:.4f} para K={self.c}).\\n\"\n",
    "                f\"Normas encontradas para esses pontos: {norms[problematic_indices]}\"\n",
    "            )\n",
    "            raise AssertionError(error_msg)\n",
    "        # print(f\"Validação da geometria de Poincaré para {X.shape[0]} pontos bem-sucedida (K={curvature}).\")\n",
    "        \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Treina o classificador KNN Hiperbólico com os dados de treinamento.\n",
    "\n",
    "        Parâmetros:\n",
    "        X (numpy.ndarray): As características dos dados de treinamento (pontos na bola de Poincaré).\n",
    "        y (numpy.ndarray): Os rótulos dos dados de treinamento.\n",
    "        \"\"\"\n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(\"O número de amostras em X e y deve ser o mesmo.\")\n",
    "        if X.shape[0] < self.k:\n",
    "             print(f\"Aviso: O número de amostras de treinamento ({X.shape[0]}) é menor que k ({self.k}).\")\n",
    "\n",
    "        if self.validate_input_geometry:\n",
    "            self._validate_poincare_points(X)\n",
    "\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X_test: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Prevê os rótulos para um conjunto de pontos de dados X_test.\n",
    "\n",
    "        Parâmetros:\n",
    "        X_test (numpy.ndarray): Os pontos de dados (na bola de Poincaré) para os quais fazer previsões.\n",
    "\n",
    "        Retorna:\n",
    "        numpy.ndarray: Um array de rótulos previstos.\n",
    "        \"\"\"\n",
    "        if self.X_train is None or self.y_train is None:\n",
    "            raise RuntimeError(\"O classificador KNN deve ser treinado com o método 'fit' antes de prever.\")\n",
    "\n",
    "        if self.validate_input_geometry:\n",
    "            self._validate_poincare_points(X_test)\n",
    "        \n",
    "        predictions = [self._predict_single(x) for x in X_test]\n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "\n",
    "    def _predict_single(self, x: np.ndarray) -> int: # Renomeado para clareza e consistência\n",
    "        \"\"\"\n",
    "        Prevê o rótulo para um único ponto de dados x na bola de Poincaré.\n",
    "\n",
    "        Parâmetros:\n",
    "        x (numpy.ndarray): O ponto de dados para o qual fazer uma previsão.\n",
    "\n",
    "        Retorna:\n",
    "        int: O rótulo previsto para o ponto de dados de entrada x.\n",
    "        \"\"\"\n",
    "        # Calcula as distâncias hiperbólicas para todos os pontos de dados de treinamento\n",
    "        # A função `hypdist` DEVE ser uma implementação correta da distância no modelo de Poincaré.\n",
    "        distances = [hypdist(x, x_train_point, c=self.c) for x_train_point in self.X_train]\n",
    "\n",
    "        # Obtém os índices dos k pontos de dados de treinamento mais próximos\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "\n",
    "        # Obtém os rótulos dos k pontos de dados de treinamento mais próximos\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "\n",
    "        # Realiza a votação majoritária para determinar o rótulo final\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dataset Iris...\n",
      "\n",
      "Iniciando modelagem em Espaço Hiperbólico (Curvatura K=0.1)...\n",
      "\n",
      "--- Resultados da Avaliação ---\n",
      "Acurácia: 1.0000\n",
      "Acurácia Balanceada: 1.0000\n",
      "Recall: 1.0000\n",
      "Precisão: 1.0000\n",
      "F1-Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# --- Configurações e Constantes ---\n",
    "SEED = 78645\n",
    "VALIDATE_INPUT_GEOMETRY = True\n",
    "CURVATURE = 0.1  # Curvatura para o espaço de Poincaré\n",
    "N_NEIGHBORS = 3  # Número de vizinhos para o KNN\n",
    "TEST_SIZE_INITIAL_SPLIT = 0.1  # Proporção para o conjunto de teste\n",
    "TEST_SIZE_VALIDATION_SPLIT = 0.1 # Proporção para o conjunto de validação (do restante)\n",
    "\n",
    "\n",
    "# Define a semente para reprodutibilidade\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# --- 1. Carregamento e Divisão dos Dados ---\n",
    "print(\"Carregando dataset Iris...\")\n",
    "iris = datasets.load_iris()\n",
    "data_np, data_labels_np = iris.data, iris.target\n",
    "\n",
    "# Divide o dataset em treino+validação e teste\n",
    "x_train_val_np, X_test_np, y_train_val_np, y_test_np = train_test_split(\n",
    "    data_np,\n",
    "    data_labels_np,\n",
    "    stratify=data_labels_np,\n",
    "    test_size=TEST_SIZE_INITIAL_SPLIT,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "# Divide o conjunto treino+validação em treino e validação\n",
    "X_train_np, X_valid_np, y_train_np, y_valid_np = train_test_split(\n",
    "    x_train_val_np,\n",
    "    y_train_val_np,\n",
    "    stratify=y_train_val_np,\n",
    "    test_size=TEST_SIZE_VALIDATION_SPLIT,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "# --- 2. Conversão para Tensores PyTorch ---\n",
    "X_train = torch.Tensor(X_train_np)\n",
    "y_train = torch.Tensor(y_train_np).long()  # Rótulos como LongTensor\n",
    "X_valid = torch.Tensor(X_valid_np)\n",
    "y_valid = torch.Tensor(y_valid_np).long()  # Rótulos como LongTensor\n",
    "X_test = torch.Tensor(X_test_np)\n",
    "y_test = torch.Tensor(y_test_np).long()    # Rótulos como LongTensor\n",
    "\n",
    "# --- 3. Transformação para o Espaço de Poincaré e Treinamento do Modelo ---\n",
    "print(f\"\\nIniciando modelagem em Espaço Hiperbólico (Curvatura K={CURVATURE})...\")\n",
    "\n",
    "# Inicializa o transformador Euclidiano para Poincaré\n",
    "e2p_transformer = ToPoincare(c=CURVATURE, train_c=False, train_x=False)\n",
    "\n",
    "# Mapeia os dados para a bola de Poincaré\n",
    "X_train_hyp = e2p_transformer(X_train)\n",
    "X_valid_hyp = e2p_transformer(X_valid)\n",
    "X_test_hyp = e2p_transformer(X_test)\n",
    "\n",
    "# Inicializa e treina o classificador KNN Hiperbólico\n",
    "hyperbolic_knn_classifier = HyperbolicKNN(k=N_NEIGHBORS, c=CURVATURE)\n",
    "hyperbolic_knn_classifier.fit(X_train_hyp, y_train)\n",
    "\n",
    "# Faz predições no conjunto de teste\n",
    "y_pred_eval = hyperbolic_knn_classifier.predict(X_test_hyp)\n",
    "\n",
    "# --- 4. Avaliação do Modelo ---\n",
    "\n",
    "# Converte tensores para arrays NumPy para uso com sklearn.metrics\n",
    "y_test_eval = y_test.cpu().numpy()\n",
    "\n",
    "accuracy = accuracy_score(y_test_eval, y_pred_eval)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test_eval, y_pred_eval)\n",
    "# average='weighted' para lidar com desbalanceamento de classes nas métricas de recall, precision, f1\n",
    "recall = recall_score(y_test_eval, y_pred_eval, average='weighted', zero_division=0)\n",
    "precision = precision_score(y_test_eval, y_pred_eval, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test_eval, y_pred_eval, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\n--- Resultados da Avaliação ---\")\n",
    "print(f\"Acurácia: {accuracy:.4f}\")\n",
    "print(f\"Acurácia Balanceada: {balanced_accuracy:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precisão: {precision:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pad-Ufes-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando modelagem em Espaço Hiperbólico (Curvatura K=0.1)...\n",
      "\n",
      "--- Resultados da Avaliação ---\n",
      "Acurácia: 0.8609\n",
      "Acurácia Balanceada: 0.8614\n",
      "Recall: 0.8609\n",
      "Precisão: 0.8616\n",
      "F1-Score: 0.8610\n"
     ]
    }
   ],
   "source": [
    "# #############################\n",
    "# # Initialize and train the KNN classifier\n",
    "# knn_classifier = KNN(k=2)  # Create a KNN classifier with k=5 neighbors\n",
    "# knn_classifier.fit(X_train, y_train)  # Train the classifier on the training data\n",
    "# y_pred = knn_classifier.predict(X_test) # Make predictions on the test data\n",
    "\n",
    "# #############################\n",
    "# KNN original - Sklearn\n",
    "# knn = KNeighborsClassifier(n_neighbors=3)\n",
    "# knn.fit(X_train, y_train)\n",
    "# y_pred = knn.predict(X_test)\n",
    "\n",
    "#############################\n",
    "# Initialize and train the KNN classifier\n",
    "\n",
    "# --- Configurações e Constantes ---\n",
    "SEED = 78645\n",
    "VALIDATE_INPUT_GEOMETRY = True\n",
    "CURVATURE = 0.1  # Curvatura para o espaço de Poincaré\n",
    "N_NEIGHBORS = 3  # Número de vizinhos para o KNN\n",
    "TEST_SIZE_INITIAL_SPLIT = 0.1  # Proporção para o conjunto de teste\n",
    "TEST_SIZE_VALIDATION_SPLIT = 0.1 # Proporção para o conjunto de validação (do restante)\n",
    "\n",
    "\n",
    "# Define a semente para reprodutibilidade\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# --- 1. Carregamento e Divisão dos Dados ---\n",
    "\n",
    "df_data = pd.read_csv('./padufes_fair_adele_fitz_mod.csv', delimiter=',')\n",
    "\n",
    "data = df_data.iloc[:, 1:]\n",
    "data_labels = df_data.iloc[:, 0]\n",
    "\n",
    "# Divide o dataset em treino+validação e teste\n",
    "x_to_train_valid, X_test_np, y_to_train_valid, y_test_np = train_test_split(\n",
    "    data,\n",
    "    data_labels,\n",
    "    stratify=data_labels,\n",
    "    test_size=TEST_SIZE_INITIAL_SPLIT,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "# Divide o conjunto treino+validação em treino e validação\n",
    "X_train_np, X_valid_np, y_train_np, y_valid_np = train_test_split(\n",
    "    x_to_train_valid,\n",
    "    y_to_train_valid,\n",
    "    stratify=y_to_train_valid,\n",
    "    test_size=TEST_SIZE_VALIDATION_SPLIT,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_np = scaler.fit_transform(X_train_np)\n",
    "X_valid_np = scaler.transform(X_valid_np)\n",
    "X_test_np = scaler.transform(X_test_np)\n",
    "\n",
    "# --- 2. Conversão para Tensores PyTorch ---\n",
    "X_train = torch.Tensor(X_train_np)\n",
    "y_train = torch.Tensor(y_train_np.values).long()  # Rótulos como LongTensor\n",
    "X_valid = torch.Tensor(X_valid_np)\n",
    "y_valid = torch.Tensor(y_valid_np.values).long()  # Rótulos como LongTensor\n",
    "X_test = torch.Tensor(X_test_np)\n",
    "y_test = torch.Tensor(y_test_np.values).long()    # Rótulos como LongTensor\n",
    "\n",
    "# --- 3. Transformação para o Espaço de Poincaré e Treinamento do Modelo ---\n",
    "print(f\"\\nIniciando modelagem em Espaço Hiperbólico (Curvatura K={CURVATURE})...\")\n",
    "\n",
    "# Inicializa o transformador Euclidiano para Poincaré\n",
    "e2p_transformer = ToPoincare(c=CURVATURE, train_c=False, train_x=False)\n",
    "\n",
    "# Mapeia os dados para a bola de Poincaré\n",
    "X_train_hyp = e2p_transformer(X_train)\n",
    "X_valid_hyp = e2p_transformer(X_valid)\n",
    "X_test_hyp = e2p_transformer(X_test)\n",
    "\n",
    "# Inicializa e treina o classificador KNN Hiperbólico\n",
    "hyperbolic_knn_classifier = HyperbolicKNN(k=N_NEIGHBORS, c=CURVATURE)\n",
    "hyperbolic_knn_classifier.fit(X_train_hyp, y_train)\n",
    "\n",
    "# Faz predições no conjunto de teste\n",
    "y_pred_eval = hyperbolic_knn_classifier.predict(X_test_hyp)\n",
    "\n",
    "# --- 4. Avaliação do Modelo ---\n",
    "\n",
    "# Converte tensores para arrays NumPy para uso com sklearn.metrics\n",
    "y_test_eval = y_test.cpu().numpy()\n",
    "\n",
    "accuracy = accuracy_score(y_test_eval, y_pred_eval)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test_eval, y_pred_eval)\n",
    "# average='weighted' para lidar com desbalanceamento de classes nas métricas de recall, precision, f1\n",
    "recall = recall_score(y_test_eval, y_pred_eval, average='weighted', zero_division=0)\n",
    "precision = precision_score(y_test_eval, y_pred_eval, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test_eval, y_pred_eval, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\n--- Resultados da Avaliação ---\")\n",
    "print(f\"Acurácia: {accuracy:.4f}\")\n",
    "print(f\"Acurácia Balanceada: {balanced_accuracy:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precisão: {precision:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando KNN - SKLEARN...\n",
      "\n",
      "--- Resultados da Avaliação ---\n",
      "Acurácia: 0.8522\n",
      "Acurácia Balanceada: 0.8531\n",
      "Recall: 0.8522\n",
      "Precisão: 0.8535\n",
      "F1-Score: 0.8523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/labcin/anaconda3/envs/mbrenv/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# --- Configurações e Constantes ---\n",
    "SEED = 78645\n",
    "VALIDATE_INPUT_GEOMETRY = True\n",
    "CURVATURE = 0.1  # Curvatura para o espaço de Poincaré\n",
    "N_NEIGHBORS = 3  # Número de vizinhos para o KNN\n",
    "TEST_SIZE_INITIAL_SPLIT = 0.1  # Proporção para o conjunto de teste\n",
    "TEST_SIZE_VALIDATION_SPLIT = 0.1 # Proporção para o conjunto de validação (do restante)\n",
    "\n",
    "\n",
    "# Define a semente para reprodutibilidade\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# --- 1. Carregamento e Divisão dos Dados ---\n",
    "\n",
    "df_data = pd.read_csv('./padufes_fair_adele_fitz_mod.csv', delimiter=',')\n",
    "\n",
    "data = df_data.iloc[:, 1:]\n",
    "data_labels = df_data.iloc[:, 0]\n",
    "\n",
    "# Divide o dataset em treino+validação e teste\n",
    "x_to_train_valid, X_test_np, y_to_train_valid, y_test_np = train_test_split(\n",
    "    data,\n",
    "    data_labels,\n",
    "    stratify=data_labels,\n",
    "    test_size=TEST_SIZE_INITIAL_SPLIT,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "# Divide o conjunto treino+validação em treino e validação\n",
    "X_train_np, X_valid_np, y_train_np, y_valid_np = train_test_split(\n",
    "    x_to_train_valid,\n",
    "    y_to_train_valid,\n",
    "    stratify=y_to_train_valid,\n",
    "    test_size=TEST_SIZE_VALIDATION_SPLIT,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_np = scaler.fit_transform(X_train_np)\n",
    "X_valid_np = scaler.transform(X_valid_np)\n",
    "X_test_np = scaler.transform(X_test_np)\n",
    "\n",
    "# --- 2. Conversão para Tensores PyTorch ---\n",
    "X_train = torch.Tensor(X_train_np)\n",
    "y_train = torch.Tensor(y_train_np.values).long()  # Rótulos como LongTensor\n",
    "X_valid = torch.Tensor(X_valid_np)\n",
    "y_valid = torch.Tensor(y_valid_np.values).long()  # Rótulos como LongTensor\n",
    "X_test = torch.Tensor(X_test_np)\n",
    "y_test = torch.Tensor(y_test_np.values).long()    # Rótulos como LongTensor\n",
    "\n",
    "# --- 3. Transformação para o Espaço de Poincaré e Treinamento do Modelo ---\n",
    "print(f\"\\nIniciando KNN - SKLEARN...\")\n",
    "\n",
    "# #############################\n",
    "# KNN original - Sklearn\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_eval = knn.predict(X_test)\n",
    "\n",
    "# --- 4. Avaliação do Modelo ---\n",
    "\n",
    "# Converte tensores para arrays NumPy para uso com sklearn.metrics\n",
    "y_test_eval = y_test.cpu().numpy()\n",
    "\n",
    "accuracy = accuracy_score(y_test_eval, y_pred_eval)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test_eval, y_pred_eval)\n",
    "# average='weighted' para lidar com desbalanceamento de classes nas métricas de recall, precision, f1\n",
    "recall = recall_score(y_test_eval, y_pred_eval, average='weighted', zero_division=0)\n",
    "precision = precision_score(y_test_eval, y_pred_eval, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test_eval, y_pred_eval, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\n--- Resultados da Avaliação ---\")\n",
    "print(f\"Acurácia: {accuracy:.4f}\")\n",
    "print(f\"Acurácia Balanceada: {balanced_accuracy:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precisão: {precision:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando KNN - Implementado...\n",
      "\n",
      "--- Resultados da Avaliação ---\n",
      "Acurácia: 0.8522\n",
      "Acurácia Balanceada: 0.8531\n",
      "Recall: 0.8522\n",
      "Precisão: 0.8535\n",
      "F1-Score: 0.8523\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_valid = np.array(X_valid)\n",
    "y_valid = np.array(y_valid)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# --- Configurações e Constantes ---\n",
    "SEED = 78645\n",
    "VALIDATE_INPUT_GEOMETRY = True\n",
    "CURVATURE = 0.1  # Curvatura para o espaço de Poincaré\n",
    "N_NEIGHBORS = 3  # Número de vizinhos para o KNN\n",
    "TEST_SIZE_INITIAL_SPLIT = 0.1  # Proporção para o conjunto de teste\n",
    "TEST_SIZE_VALIDATION_SPLIT = 0.1 # Proporção para o conjunto de validação (do restante)\n",
    "\n",
    "\n",
    "# Define a semente para reprodutibilidade\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# --- 1. Carregamento e Divisão dos Dados ---\n",
    "\n",
    "df_data = pd.read_csv('./padufes_fair_adele_fitz_mod.csv', delimiter=',')\n",
    "\n",
    "data = df_data.iloc[:, 1:]\n",
    "data_labels = df_data.iloc[:, 0]\n",
    "\n",
    "# Divide o dataset em treino+validação e teste\n",
    "x_to_train_valid, X_test_np, y_to_train_valid, y_test_np = train_test_split(\n",
    "    data,\n",
    "    data_labels,\n",
    "    stratify=data_labels,\n",
    "    test_size=TEST_SIZE_INITIAL_SPLIT,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "# Divide o conjunto treino+validação em treino e validação\n",
    "X_train_np, X_valid_np, y_train_np, y_valid_np = train_test_split(\n",
    "    x_to_train_valid,\n",
    "    y_to_train_valid,\n",
    "    stratify=y_to_train_valid,\n",
    "    test_size=TEST_SIZE_VALIDATION_SPLIT,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_np = scaler.fit_transform(X_train_np)\n",
    "X_valid_np = scaler.transform(X_valid_np)\n",
    "X_test_np = scaler.transform(X_test_np)\n",
    "\n",
    "# --- 2. Conversão para Tensores PyTorch ---\n",
    "# X_train = torch.Tensor(X_train_np)\n",
    "# y_train = torch.Tensor(y_train_np.values).long()  # Rótulos como LongTensor\n",
    "# X_valid = torch.Tensor(X_valid_np)\n",
    "# y_valid = torch.Tensor(y_valid_np.values).long()  # Rótulos como LongTensor\n",
    "# X_test = torch.Tensor(X_test_np)\n",
    "# y_test = torch.Tensor(y_test_np.values).long()    # Rótulos como LongTensor\n",
    "\n",
    "# --- 3. Transformação para o Espaço de Poincaré e Treinamento do Modelo ---\n",
    "print(f\"\\nIniciando KNN - Implementado...\")\n",
    "\n",
    "# #############################\n",
    "# KNN original - Sklearn\n",
    "knn_classifier = KNN(k=3)  # Create a KNN classifier with k=5 neighbors\n",
    "knn_classifier.fit(X_train, y_train)  # Train the classifier on the training data\n",
    "y_pred_eval = knn_classifier.predict(X_test) # Make predictions on the test data\n",
    "\n",
    "\n",
    "# --- 4. Avaliação do Modelo ---\n",
    "\n",
    "# Converte tensores para arrays NumPy para uso com sklearn.metrics\n",
    "y_test_eval = y_test\n",
    "\n",
    "accuracy = accuracy_score(y_test_eval, y_pred_eval)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test_eval, y_pred_eval)\n",
    "# average='weighted' para lidar com desbalanceamento de classes nas métricas de recall, precision, f1\n",
    "recall = recall_score(y_test_eval, y_pred_eval, average='weighted', zero_division=0)\n",
    "precision = precision_score(y_test_eval, y_pred_eval, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test_eval, y_pred_eval, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\n--- Resultados da Avaliação ---\")\n",
    "print(f\"Acurácia: {accuracy:.4f}\")\n",
    "print(f\"Acurácia Balanceada: {balanced_accuracy:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precisão: {precision:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbrenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
